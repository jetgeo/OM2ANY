{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from NVDB and convert to RDF for comparision with Overture Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Føyer C:\\DATA\\GitHub\\vegvesen\\NVDB-Datakatalogen\\owl til søkestien\n"
     ]
    }
   ],
   "source": [
    "import sys, datetime\n",
    "from rdflib import Graph, Namespace\n",
    "import nvdbapiv3\n",
    "from nvdb2rdf import *\n",
    "import geopandas as gpd\n",
    "from shapely import Point, wkt, LineString\n",
    "from shapely.geometry import shape, box\n",
    "from shapely.wkb import loads\n",
    "import pandas as pd\n",
    "import pyproj\n",
    "import overturemaps\n",
    "from lonboard import Map, PolygonLayer, PathLayer, ScatterplotLayer\n",
    "from lonboard.colormap import apply_continuous_cmap\n",
    "from lonboard import viz\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "rootPath = \"C:\\\\Data\\\\GitHub\\\\jetgeo\\\\OM2ANY\"\n",
    "\n",
    "#NVDB Paths\n",
    "nvdbOtlFilePath = \"C:\\\\Data\\\\GitHub\\\\jetgeo\\\\OM2ANY\\\\OWL\\\\nvdb\\\\nvdb-owl.ttl\"\n",
    "nvdbVoIRI = \"https://ontologi.atlas.vegvesen.no/nvdb/core/nvdb-owl/vegobjekt#\"\n",
    "nvdbVnIRI = \"https://ontologi.atlas.vegvesen.no/nvdb/core/vegnett#\"\n",
    "nvdbOtlIRI = \"https://ontologi.atlas.vegvesen.no/nvdb/core/nvdb-owl#\"\n",
    "\n",
    "#INSPIRE Paths\n",
    "itnrOtlFilePath = \"C:\\\\Data\\\\GitHub\\\\jetgeo\\\\OM2ANY\\\\OWL\\\\inspire\\\\itnr-owl.ttl\"\n",
    "itnrOtlIRI = \"http://inspire.ec.europa.eu/ont\"\n",
    "featuretypeid = 105\n",
    "knr = 3403\n",
    "utsnitt = 'modi.geojson'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------------\n",
    "startTime = datetime.datetime.now()\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "# Leser NVDB-ontologien til graf for objekttypebiblioteker\n",
    "print(str(datetime.datetime.now()) + ' Leser inn NVDB-OTL fra ', nvdbOtlFilePath)\n",
    "otl_nvdb = Graph()\n",
    "otl_nvdb.parse(nvdbOtlFilePath, format=\"turtle\")\n",
    "# Leser INSPIRE-ontologien til egen graf\n",
    "print(str(datetime.datetime.now()) + ' Leser inn INSPIRE-OTL fra ', itnrOtlFilePath)\n",
    "otl_itnr = Graph()\n",
    "otl_itnr.parse(itnrOtlFilePath, format=\"turtle\")\n",
    "#Slår sammen alle ontologier til en stor graf\n",
    "print(str(datetime.datetime.now()) + ' Slår sammen ontologiene')\n",
    "otl = Graph()\n",
    "otl = otl_nvdb + otl_itnr \n",
    "# Setter opp graf og namespace-forkortelser for NVDB-data\n",
    "print(str(datetime.datetime.now()) + ' Setter opp graf og namespace-forkortelser for data')\n",
    "g_nvdb=Graph()\n",
    "g_nvdb.bind(\"nvdb_vo\", Namespace(nvdbVoIRI)) #IRI for NVDB-Objekter\n",
    "g_nvdb.bind(\"nvdb_vn\", Namespace(nvdbVnIRI)) #IRI for NVDB Vegnett\n",
    "g_nvdb.bind(\"nvdb_otl\",Namespace(nvdbOtlIRI))\n",
    "g_nvdb.bind(\"gsp\",'http://www.opengis.net/ont/geosparql#')\n",
    "g_nvdb.bind(\"nvdb_otl\",Namespace(nvdbOtlIRI))\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from NVDB and convert to RDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_nvdb = nvdb2graph(featuretypeid, knr, otl_nvdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print to Turtle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = rootPath + \"\\\\data\\\\nvdb_\" + str(featuretypeid) + \"_\" + str(knr) + \".ttl.\"\n",
    "print(str(datetime.datetime.now()) + ' Skriver til NVDB-Turtle-fil: ' + fileName)\n",
    "g_nvdb.serialize(destination=fileName, format=\"turtle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read road network from NVDB and create GeoDataFrames with links and nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates of the polygon feature: 283646.630245 6550974.166444, 290696.263405 6552761.073827, 290798.107492 6559552.695475, 286687.386750 6571174.505270, 278959.847715 6582843.761427, 261459.965387 6592816.360618, 261684.402907 6602897.758014, 253986.688583 6604474.483078, 252409.898995 6592726.902924, 262426.088473 6584522.198264, 274228.569390 6573790.349457, 280837.881236 6561058.296764, 283646.630245 6550974.166444\n"
     ]
    }
   ],
   "source": [
    "# Read GeoJSON Polygon, transform to EPSG:5973 and use for filtering NVDB\n",
    "gjFile = rootPath + \"\\\\Data\\\\\" + utsnitt\n",
    "\n",
    "# Bounding box\n",
    "import geojson\n",
    "from shapely.geometry import shape\n",
    "\n",
    "def get_bbox(geometry):\n",
    "    polygon = shape(geometry)\n",
    "    return polygon.bounds\n",
    "\n",
    "gjP4326 = gpd.read_file(gjFile)\n",
    "gjP5973 = gjP4326.to_crs(epsg=5973)\n",
    "\n",
    "polygon_coords = gjP5973.geometry.iloc[0].exterior.coords\n",
    "\n",
    "# Create a string with the coordinates separated by commas\n",
    "coords_string = \", \".join([f\"{x:.6f} {y:.6f}\" for x, y in polygon_coords])\n",
    "\n",
    "# Print the coordinates string\n",
    "print(f\"Coordinates of the polygon feature: {coords_string}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter: {'polygon': '283646.630245 6550974.166444, 290696.263405 6552761.073827, 290798.107492 6559552.695475, 286687.386750 6571174.505270, 278959.847715 6582843.761427, 261459.965387 6592816.360618, 261684.402907 6602897.758014, 253986.688583 6604474.483078, 252409.898995 6592726.902924, 262426.088473 6584522.198264, 274228.569390 6573790.349457, 280837.881236 6561058.296764, 283646.630245 6550974.166444'}\n"
     ]
    }
   ],
   "source": [
    "# Read from NVDB\n",
    "v = nvdbapiv3.nvdbVegnett()\n",
    "v.filter({'polygon' : coords_string})\n",
    "# v.filter( { 'kommune' : knr } )\n",
    "print(\"Filter: \" + str(v.filterdata))\n",
    "\n",
    "#Convert to GeoDataFrame\n",
    "sDf = pd.DataFrame(v.to_records())\n",
    "#Remove 'vegtrase' links\n",
    "sDf = sDf[sDf['detaljnivå'] != 'Vegtrase']\n",
    "sDf['geometry'] = sDf['geometri'].apply( wkt.loads )\n",
    "sGDF = gpd.GeoDataFrame( sDf, geometry='geometry', crs=5973 )\n",
    "\n",
    "# Convert start and end coordinates to Shapely Point geometries\n",
    "startpoints = [Point(coords[0]) for coords in sGDF['geometry'].apply(lambda line: line.coords)]\n",
    "endpoints = [Point(coords[-1]) for coords in sGDF['geometry'].apply(lambda line: line.coords)]\n",
    "# Create GeoDataFrame with nodes \n",
    "nGDF = gpd.GeoDataFrame({\n",
    "    'geometry': startpoints + endpoints,\n",
    "    'nodeid': sGDF['startnode'].tolist() + sGDF['sluttnode'].tolist(),\n",
    "}, crs=sGDF.crs)\n",
    "# Remove duplicate nodes in the GeoDataFrame\n",
    "nGDF.drop_duplicates(subset='nodeid', inplace=True)\n",
    "\n",
    "#Write to GeoJSON files\n",
    "sGDF.to_file(rootPath + \"\\\\data\\\\nvdb\\\\nvdb_Segments.geojson\", driver=\"GeoJSON\")\n",
    "nGDF.to_file(rootPath + \"\\\\data\\\\nvdb\\\\nvdb_Nodes.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find nodes that connects more than two road segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      geometry   nodeid\n",
      "0      POINT Z (256058.115 6604216.822 37.710)   458246\n",
      "1      POINT Z (256114.690 6604114.350 37.030)  2039960\n",
      "4      POINT Z (257061.129 6603021.996 22.954)   458897\n",
      "5      POINT Z (257150.412 6602981.498 24.162)  2065319\n",
      "6      POINT Z (257187.430 6602963.900 21.020)   458973\n",
      "...                                        ...      ...\n",
      "70218  POINT Z (278575.490 6577371.360 37.470)  3509366\n",
      "70264  POINT Z (278049.620 6576938.980 27.410)  3509377\n",
      "70336  POINT Z (278865.050 6578302.710 40.470)  3514659\n",
      "71206   POINT Z (254352.200 6596969.150 3.770)  3607667\n",
      "72008  POINT Z (286761.730 6560473.970 28.910)  3819706\n",
      "\n",
      "[15323 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to count the occurrences of each node in the 'startnode' and 'endnode' columns\n",
    "node_counts = pd.concat([\n",
    "    sGDF['startnode'].value_counts(),\n",
    "    sGDF['sluttnode'].value_counts()\n",
    "], axis=1, keys=['startnode', 'sluttnode']).fillna(0)\n",
    "\n",
    "# Filter nodes that connect to more than 2 segments\n",
    "multi_segment_nodes = node_counts[(node_counts['startnode'] + node_counts['sluttnode']) > 2].index.tolist()\n",
    "# Create the new node GeoDataFrame based on 'nodeid'\n",
    "filtered_nodes_gdf = nGDF[nGDF['nodeid'].isin(multi_segment_nodes)]\n",
    "filtered_nodes_gdf.to_file(rootPath + \"\\\\data\\\\nvdb\\\\nvdb_NodesFiltered.geojson\", driver=\"GeoJSON\")\n",
    "print(filtered_nodes_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to NVDB data to WGS 84 (EPSG:4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sGDF4326 = sGDF.to_crs(epsg=4326)\n",
    "sGDF4326.crs=\"EPSG:4326\"\n",
    "nGDF4326 = nGDF.to_crs(epsg=4326)\n",
    "nGDF4326.crs=\"EPSG:4326\"\n",
    "#nGDF4326.to_file(rootPath + \"\\\\data\\\\nvdb\\\\nvdb_Nodes4326.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find extent of the NVDB Data and create a bounding box in EPSG:4326\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10.607018549727396, 59.07095720324578, 11.310705049506575, 59.531880931884736)\n"
     ]
    }
   ],
   "source": [
    "# Get the overall bounding box (extent) for all geometries\n",
    "minx, miny, maxx, maxy = sGDF.total_bounds\n",
    "\n",
    "# Create a Shapely bounding box\n",
    "bounding_box = box(minx, miny, maxx, maxy)\n",
    "\n",
    "# Create a PyProj transformer for EPSG:5973 to EPSG:4326\n",
    "transformer = pyproj.Transformer.from_crs(\"EPSG:5973\", \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "# Transform the bounding box coordinates to EPSG:4326\n",
    "minlon, minlat = transformer.transform(minx, miny)\n",
    "maxlon, maxlat = transformer.transform(maxx, maxy)\n",
    "\n",
    "# Create a  bounding box in EPSG:4326\n",
    "bbox = minlon, minlat, maxlon, maxlat\n",
    "print(bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Overture Segments and Nodes within the BBox and store in GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbr2GDF(rbr):\n",
    "    #Convert Record Batch Reader to GeoDataFrame\n",
    "    # Extract the binary geometry column\n",
    "    binary_geometry = rbr['geometry']\n",
    "    # Convert binary geometry to Shapely geometries\n",
    "    geometries = [loads(geom.as_py()) for geom in binary_geometry]\n",
    "    # Create a Pandas DataFrame with the geometries \n",
    "    df = rbr.to_pandas()\n",
    "    df['geometry'] = geometries\n",
    "    # df['id'] = df['id']  \n",
    "    # Create a GeoDataFrame with the geometries \n",
    "    gdf = gpd.GeoDataFrame(df, geometry='geometry',crs=4326)\n",
    "    return gdf\n",
    "\n",
    "ft= \"segment\"\n",
    "segTable = overturemaps.record_batch_reader(ft, bbox).read_all()\n",
    "# Temporarily required as of Lonboard 0.8 to avoid a Lonboard bug\n",
    "segTable = segTable.combine_chunks()\n",
    "segGDF = rbr2GDF(segTable)\n",
    "# print(segGDF.head(10))\n",
    "\n",
    "ft= \"connector\"\n",
    "conTable = overturemaps.record_batch_reader(ft, bbox).read_all()\n",
    "conGDF = rbr2GDF(conTable)\n",
    "# print(conGDF.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip within polygon\n",
    "segGDF_clipped = gpd.sjoin(segGDF, gjP4326, predicate='within')\n",
    "segGDF = segGDF_clipped\n",
    "conGDF_clipped = gpd.sjoin(conGDF, gjP4326, predicate='within')\n",
    "conGDF = conGDF_clipped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export to GeoJSON, for use in QGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_filtered = segGDF[['id', 'geometry']]\n",
    "gdf_filtered.to_file(rootPath + \"\\\\data\\\\om\\\\om_segments.geojson\", driver=\"GeoJSON\")\n",
    "gdf_filtered = conGDF[['id', 'geometry']]\n",
    "gdf_filtered.to_file(rootPath + \"\\\\data\\\\om\\\\om_connectors.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show in lonboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JETKNU\\AppData\\Roaming\\Python\\Python312\\site-packages\\lonboard\\_geoarrow\\ops\\reproject.py:23: UserWarning: No CRS exists on data. If no data is shown on the map, double check that your CRS is WGS84.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55caea338904dfeabf7ff9d6fda04d9",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Map(layers=[PathLayer(get_color=[0, 0, 139], table=pyarrow.Table\n",
       "id: string\n",
       "bbox: struct<xmax: double, xmin: d…"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segLayer = PathLayer(\n",
    "    table=segTable, get_color=[0, 0, 139], width_min_pixels=1\n",
    ")\n",
    "conLayer = ScatterplotLayer(\n",
    "    table=conTable,get_fill_color=[255, 0, 0]\n",
    ")\n",
    "\n",
    "nodeLayer = ScatterplotLayer.from_geopandas(conGDF,get_fill_color=[155, 75, 0]\n",
    ")\n",
    "sLayer = PathLayer.from_geopandas(segGDF, get_color=[0, 0, 139], width_min_pixels=1)\n",
    "\n",
    "view_state = {\n",
    "    \"longitude\": 11.08,\n",
    "    \"latitude\": 60.795,\n",
    "    \"zoom\": 13,\n",
    "    \"pitch\": 0,\n",
    "    \"bearing\": 0,\n",
    "}\n",
    "\n",
    "m = Map([sLayer], view_state=view_state,_height=1000)\n",
    "# m = Map([segLayer,conLayer], view_state=view_state,_height=1000)\n",
    "m\n",
    "\n",
    "#Note: lonboard fucks up the presentation of NVDB data, wrong positioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      geometry   nodeid  index_right\n",
      "0      POINT Z (256058.115 6604216.822 37.710)   458246          NaN\n",
      "1      POINT Z (256114.690 6604114.350 37.030)  2039960          NaN\n",
      "3      POINT Z (257150.412 6602981.498 24.162)  2065319          NaN\n",
      "8      POINT Z (257828.160 6602009.950 58.955)   459406          NaN\n",
      "11     POINT Z (256427.400 6604624.200 51.809)   458569          NaN\n",
      "...                                        ...      ...          ...\n",
      "15314  POINT Z (278839.180 6580160.910 56.360)  3506961          NaN\n",
      "15315  POINT Z (276744.950 6579042.900 35.200)  3507634          NaN\n",
      "15316  POINT Z (276899.550 6578927.560 30.290)  3507657          NaN\n",
      "15318  POINT Z (278575.490 6577371.360 37.470)  3509366          NaN\n",
      "15322  POINT Z (286761.730 6560473.970 28.910)  3819706          NaN\n",
      "\n",
      "[5111 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "conOM5973 = conGDF.to_crs(epsg=5973)\n",
    "conOM5973.crs=\"EPSG:5973\"\n",
    "\n",
    "# Find points in gdf1 that are not within max_deviation distance of any point in gdf2:\n",
    "# Reset the indices of both GeoDataFrames\n",
    "filtered_nodes_gdf = filtered_nodes_gdf.reset_index(drop=True)\n",
    "conOM5973 = conOM5973.reset_index(drop=True)\n",
    "\n",
    "# Buffer the `conOM5973` GeoDataFrame by 3.0 meter\n",
    "buffered_conOM5973 = conOM5973.buffer(3.0)\n",
    "# Assuming `buffered_conOM5973` is a GeoSeries, convert it to a GeoDataFrame\n",
    "buffered_conOM5973_gdf = gpd.GeoDataFrame(geometry=buffered_conOM5973)\n",
    "\n",
    "# Perform a spatial join\n",
    "joined_df = gpd.sjoin(filtered_nodes_gdf, buffered_conOM5973_gdf, how=\"left\", predicate=\"within\")\n",
    "\n",
    "# Filter out points that did not intersect with any point in `conOM5973`\n",
    "missing_in_om = joined_df[joined_df[\"index_right\"].isna()]\n",
    "\n",
    "# Save the result to a GeoJSON file\n",
    "missing_in_om.to_file(rootPath + \"\\\\data\\\\nvdb\\\\missing_in_om.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "print(missing_in_om)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Compare restrictions\n",
    "\n",
    "# 1. Derive geometry for speedlimits, access and prohibited transitions\n",
    "\n",
    "# Linear referencing in Python: \n",
    "# - ShapelyM? https://pypi.org/project/shapelyM/\n",
    "# - linref? https://pypi.org/project/linref/\n",
    "# - https://shapely.readthedocs.io/en/stable/manual.html#linear-referencing-methods\n",
    "\n",
    "# 2. Export to GeoJSON for viewing in QGIS\n",
    "# 3. Find NVDB-LR for the geometries\n",
    "\n",
    "    # line_df['geometry'] = line_df.apply(lambda row: LineString([(row[start_m], 0), (row[end_m], 0)]), axis=1)\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "# Example LineString (replace with your actual data)\n",
    "road_segment = LineString([(0, 0), (10, 0)])\n",
    "\n",
    "# Calculate the split distances (10% from both ends)\n",
    "split_distance_start = 0.1 * road_segment.length\n",
    "split_distance_end = 0.9 * road_segment.length\n",
    "\n",
    "# Create two new LineStrings\n",
    "part1 = LineString(road_segment.coords[:int(split_distance_start)])\n",
    "part2 = LineString(road_segment.coords[int(split_distance_end):])\n",
    "\n",
    "print(part1)  # The remaining part after removing the first 10%\n",
    "print(part2)  # The remaining middle part"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
