{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from NVDB and convert to RDF for comparision with Overture Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Føyer C:\\DATA\\GitHub\\vegvesen\\NVDB-Datakatalogen\\owl til søkestien\n"
     ]
    }
   ],
   "source": [
    "import sys, datetime\n",
    "from rdflib import Graph, Namespace\n",
    "import nvdbapiv3\n",
    "from nvdb2rdf import *\n",
    "import geopandas as gpd\n",
    "from shapely import Point, wkt\n",
    "from shapely.geometry import shape, box\n",
    "from shapely.wkb import loads\n",
    "import pandas as pd\n",
    "import pyproj\n",
    "import overturemaps\n",
    "from lonboard import Map, PolygonLayer, PathLayer, ScatterplotLayer\n",
    "from lonboard.colormap import apply_continuous_cmap\n",
    "from lonboard import viz\n",
    "\n",
    "# Parameters\n",
    "rootPath = \"C:\\\\Data\\\\GitHub\\\\jetgeo\\\\OM2ANY\"\n",
    "\n",
    "#NVDB Paths\n",
    "nvdbOtlFilePath = \"C:\\\\Data\\\\GitHub\\\\jetgeo\\\\OM2ANY\\\\OWL\\\\nvdb\\\\nvdb-owl.ttl\"\n",
    "nvdbVoIRI = \"https://ontologi.atlas.vegvesen.no/nvdb/core/nvdb-owl/vegobjekt#\"\n",
    "nvdbVnIRI = \"https://ontologi.atlas.vegvesen.no/nvdb/core/vegnett#\"\n",
    "nvdbOtlIRI = \"https://ontologi.atlas.vegvesen.no/nvdb/core/nvdb-owl#\"\n",
    "\n",
    "#INSPIRE Paths\n",
    "itnrOtlFilePath = \"C:\\\\Data\\\\GitHub\\\\jetgeo\\\\OM2ANY\\\\OWL\\\\inspire\\\\itnr-owl.ttl\"\n",
    "itnrOtlIRI = \"http://inspire.ec.europa.eu/ont\"\n",
    "featuretypeid = 105\n",
    "knr = 3403\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------------\n",
    "startTime = datetime.datetime.now()\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "# Leser NVDB-ontologien til graf for objekttypebiblioteker\n",
    "print(str(datetime.datetime.now()) + ' Leser inn NVDB-OTL fra ', nvdbOtlFilePath)\n",
    "otl_nvdb = Graph()\n",
    "otl_nvdb.parse(nvdbOtlFilePath, format=\"turtle\")\n",
    "# Leser INSPIRE-ontologien til egen graf\n",
    "print(str(datetime.datetime.now()) + ' Leser inn INSPIRE-OTL fra ', itnrOtlFilePath)\n",
    "otl_itnr = Graph()\n",
    "otl_itnr.parse(itnrOtlFilePath, format=\"turtle\")\n",
    "#Slår sammen alle ontologier til en stor graf\n",
    "print(str(datetime.datetime.now()) + ' Slår sammen ontologiene')\n",
    "otl = Graph()\n",
    "otl = otl_nvdb + otl_itnr \n",
    "# Setter opp graf og namespace-forkortelser for NVDB-data\n",
    "print(str(datetime.datetime.now()) + ' Setter opp graf og namespace-forkortelser for data')\n",
    "g_nvdb=Graph()\n",
    "g_nvdb.bind(\"nvdb_vo\", Namespace(nvdbVoIRI)) #IRI for NVDB-Objekter\n",
    "g_nvdb.bind(\"nvdb_vn\", Namespace(nvdbVnIRI)) #IRI for NVDB Vegnett\n",
    "g_nvdb.bind(\"nvdb_otl\",Namespace(nvdbOtlIRI))\n",
    "g_nvdb.bind(\"gsp\",'http://www.opengis.net/ont/geosparql#')\n",
    "g_nvdb.bind(\"nvdb_otl\",Namespace(nvdbOtlIRI))\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from NVDB and convert to RDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_nvdb = nvdb2graph(featuretypeid, knr, otl_nvdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print to Turtle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = rootPath + \"\\\\data\\\\nvdb_\" + str(featuretypeid) + \"_\" + str(knr) + \".ttl.\"\n",
    "print(str(datetime.datetime.now()) + ' Skriver til NVDB-Turtle-fil: ' + fileName)\n",
    "g_nvdb.serialize(destination=fileName, format=\"turtle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read road network from NVDB and create GeoDataFrames with links and nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter: {'kommune': 3403}\n"
     ]
    }
   ],
   "source": [
    "v = nvdbapiv3.nvdbVegnett()\n",
    "v.filter( { 'kommune' : knr } )\n",
    "print(\"Filter: \" + str(v.filterdata))\n",
    "\n",
    "#Convert to GeoDataFrame\n",
    "sDf = pd.DataFrame(v.to_records())\n",
    "sDf['geometry'] = sDf['geometri'].apply( wkt.loads )\n",
    "sGDF = gpd.GeoDataFrame( sDf, geometry='geometry', crs=5973 )\n",
    "sGDF.to_file(rootPath + \"\\\\data\\\\nvdb\\\\nvdb_Segments.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "\n",
    "# Convert start and end coordinates to Shapely Point geometries\n",
    "startpoints = [Point(coords[0]) for coords in sGDF['geometry'].apply(lambda line: line.coords)]\n",
    "endpoints = [Point(coords[-1]) for coords in sGDF['geometry'].apply(lambda line: line.coords)]\n",
    "\n",
    "nGDF = gpd.GeoDataFrame({\n",
    "    'geometry': startpoints + endpoints,\n",
    "    'nodeid': sGDF['startnode'].tolist() + sGDF['sluttnode'].tolist(),\n",
    "}, crs=sGDF.crs)\n",
    "\n",
    "nGDF.drop_duplicates(subset='nodeid', inplace=True)\n",
    "nGDF.to_file(rootPath + \"\\\\data\\\\nvdb\\\\nvdb_Nodes.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to NVDB data to WGS 84 (EPSG:4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sGDF4326 = sGDF.to_crs(epsg=4326)\n",
    "sGDF4326.crs=\"EPSG:4326\"\n",
    "nGDF4326 = nGDF.to_crs(epsg=4326)\n",
    "nGDF4326.crs=\"EPSG:4326\"\n",
    "#nGDF4326.to_file(rootPath + \"\\\\data\\\\nvdb\\\\nvdb_Nodes4326.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find extent of the NVDB Data and create a bounding box in EPSG:4326\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the overall bounding box (extent) for all geometries\n",
    "minx, miny, maxx, maxy = sGDF.total_bounds\n",
    "\n",
    "# Create a Shapely bounding box\n",
    "bounding_box = box(minx, miny, maxx, maxy)\n",
    "\n",
    "# Create a PyProj transformer for EPSG:5973 to EPSG:4326\n",
    "transformer = pyproj.Transformer.from_crs(\"EPSG:5973\", \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "# Transform the bounding box coordinates to EPSG:4326\n",
    "minlon, minlat = transformer.transform(minx, miny)\n",
    "maxlon, maxlat = transformer.transform(maxx, maxy)\n",
    "\n",
    "# Create a  bounding box in EPSG:4326\n",
    "bbox = minlon, minlat, maxlon, maxlat\n",
    "print(bbox)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Overture Segments and Nodes within the BBox and store in GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbr2GDF(rbr):\n",
    "    #Convert Record Batch Reader to GeoDataFrame\n",
    "    # Extract the binary geometry column\n",
    "    binary_geometry = rbr['geometry']\n",
    "    # Convert binary geometry to Shapely geometries\n",
    "    geometries = [loads(geom.as_py()) for geom in binary_geometry]\n",
    "    # Create a Pandas DataFrame with the geometries \n",
    "    df = rbr.to_pandas()\n",
    "    df['geometry'] = geometries\n",
    "    # df['id'] = df['id']  \n",
    "    # Create a GeoDataFrame with the geometries \n",
    "    gdf = gpd.GeoDataFrame(df, geometry='geometry',crs=4326)\n",
    "    return gdf\n",
    "\n",
    "ft= \"segment\"\n",
    "segTable = overturemaps.record_batch_reader(ft, bbox).read_all()\n",
    "# Temporarily required as of Lonboard 0.8 to avoid a Lonboard bug\n",
    "segTable = segTable.combine_chunks()\n",
    "segGDF = rbr2GDF(segTable)\n",
    "# print(segGDF.head(10))\n",
    "\n",
    "\n",
    "ft= \"connector\"\n",
    "conTable = overturemaps.record_batch_reader(ft, bbox).read_all()\n",
    "conGDF = rbr2GDF(conTable)\n",
    "# print(conGDF.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export to GeoJSON, for use in QGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_filtered = segGDF[['id', 'geometry']]\n",
    "gdf_filtered.to_file(rootPath + \"\\\\data\\\\om\\\\om_segments.geojson\", driver=\"GeoJSON\")\n",
    "gdf_filtered = conGDF[['id', 'geometry']]\n",
    "gdf_filtered.to_file(rootPath + \"\\\\data\\\\om\\\\om_connectors.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show in lonboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segLayer = PathLayer(\n",
    "#     table=segTable, get_color=[0, 0, 139], width_min_pixels=1\n",
    "# )\n",
    "# conLayer = ScatterplotLayer(\n",
    "#     table=conTable,get_fill_color=[255, 0, 0]\n",
    "# )\n",
    "\n",
    "nodeLayer = ScatterplotLayer.from_geopandas(nGDF4326,get_fill_color=[155, 75, 0]\n",
    ")\n",
    "sLayer = PathLayer.from_geopandas(sGDF4326, get_color=[0, 0, 139], width_min_pixels=1)\n",
    "\n",
    "view_state = {\n",
    "    \"longitude\": 11.08,\n",
    "    \"latitude\": 60.795,\n",
    "    \"zoom\": 13,\n",
    "    \"pitch\": 0,\n",
    "    \"bearing\": 0,\n",
    "}\n",
    "\n",
    "m = Map([sLayer,nodeLayer], view_state=view_state,_height=1000)\n",
    "# m = Map([segLayer,conLayer,nodeLayer], view_state=view_state,_height=1000)\n",
    "m\n",
    "\n",
    "#Note: lonboard fucks up the presentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Assuming you have GeoDataFrames 'gdf1' and 'gdf2' with point geometries\n",
    "# and a specified maximum deviation (max_deviation)\n",
    "\n",
    "# Spatial join to find points within max_deviation distance\n",
    "joined = gpd.sjoin(gdf1, gdf2, op=\"within\", distance_col=\"distance\")\n",
    "\n",
    "# Filter out points within max_deviation\n",
    "missing_points = joined[joined[\"distance\"] > max_deviation]\n",
    "\n",
    "# Extract the missing points\n",
    "missing_points_geom = missing_points.geometry\n",
    "\n",
    "# If you want the missing points as a list of tuples (x, y):\n",
    "missing_points_list = [(point.x, point.y) for point in missing_points_geom]\n",
    "\n",
    "print(f\"Missing points: {missing_points_list}\")\n",
    "\n",
    "# The approach I provided using gpd.sjoin identifies points that are within the specified distance in both GeoDataFrames. \n",
    "# To find points missing in either gdf1 or gdf2, you can follow these steps:\n",
    "# Find points in gdf1 that are not within max_deviation distance of any point in gdf2:\n",
    "missing_in_gdf1 = gdf1[~gdf1.intersects(gdf2.buffer(max_deviation))]\n",
    "# Find points in gdf2 that are not within max_deviation distance of any point in gdf1:\n",
    "missing_in_gdf2 = gdf2[~gdf2.intersects(gdf1.buffer(max_deviation))]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
