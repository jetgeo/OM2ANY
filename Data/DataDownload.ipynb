{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Overture Maps with DuckDB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is DuckDB?\n",
    "DuckDB is designed to support analytical query workloads, also known as Online analytical processing (OLAP). It includes a columnar-vectorized query execution engine. This is more performant than traditional systems such as PostgreSQL, MySQL, or SQLite, which process each row sequentially. There are many plugins available. You can easily transfer your data in environments such as Amazon S3, Google Cloud Storage, postgresql using plugins. You can perform spatial analysis by installing the Spatial plugin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import overturemaps\n",
    "import geopandas as gpd\n",
    "db = duckdb.connect(\"data.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing plug-ins for data access and spatial analysis\n",
    "We install the \"spatial\" plugin to perform spatial analysis.\n",
    "We are installing the \"httpfs\" plugin to access POI data in Amazon S3. Then we define the region as \"us-west-2\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.sql(\"\"\"\n",
    "INSTALL spatial;\n",
    "INSTALL httpfs;\n",
    "LOAD spatial;\n",
    "LOAD httpfs;\n",
    "SET s3_region='us-west-2';\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "release = \"2024-04-16-beta.0\"\n",
    "theme = \"transportation\"\n",
    "ptype = \"segment\"\n",
    "bbFile = \"C:\\\\Data\\\\GitHub\\\\jetgeo\\\\OM2UML\\\\Data\\\\hamar.geojson\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the bounding box to search within. Use https://geojson.io/ to create a bounding box for your area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Box (minx, miny, maxx, maxy): (11.055774, 60.789123, 11.103776, 60.80348)\n"
     ]
    }
   ],
   "source": [
    "# Bounding box\n",
    "import geojson\n",
    "from shapely.geometry import shape\n",
    "\n",
    "def get_bbox(geometry):\n",
    "    polygon = shape(geometry)\n",
    "    return polygon.bounds\n",
    "\n",
    "with open(bbFile) as f:\n",
    "    gj = geojson.load(f)\n",
    "    features = gj['features'][0]  # Assuming you want the first feature\n",
    "\n",
    "bbox = get_bbox(features['geometry'])\n",
    "print(\"Bounding Box (minx, miny, maxx, maxy):\", bbox)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data and count the number of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bbox = -74.02169, 40.696423, -73.891338, 40.831263\n",
    "table = overturemaps.record_batch_reader(\"building\", bbox).read_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.sql(\"\"\"\n",
    "#   create table places as \n",
    "#   select * from read_parquet('s3://overturemaps-us-west-2/release/2023-07-26-alpha.0/theme=places/type=*/*')\n",
    "# \"\"\")\n",
    "try:\n",
    "    db.sql(\"\"\"DROP VIEW \"\"\" + ptype)\n",
    "except:\n",
    "    print(\"No existing table \" + ptype)    \n",
    "\n",
    "strSql= \"\"\"CREATE VIEW \"\"\" + ptype + \"\"\" AS \n",
    "       SELECT * FROM read_parquet('s3://overturemaps-us-west-2/release/\"\"\" + release + \"\"\"/theme=\"\"\"+ theme + \"\"\"/type=\"\"\" + ptype + \"\"\"/*', filename=true, hive_partitioning=1)\n",
    "       WHERE \n",
    "              bbox.minx > \"\"\" + str(bbox[0])+ \"\"\" AND \n",
    "              bbox.miny > \"\"\" + str(bbox[1])+ \"\"\" AND\n",
    "              bbox.maxx < \"\"\" + str(bbox[2])+ \"\"\" AND \n",
    "              bbox.maxy < \"\"\" + str(bbox[3])+ \"\"\" ;\n",
    "       \"\"\"\n",
    "# print(strSql)\n",
    "db.sql(strSql)\n",
    "db.sql(\"\"\"select count(*) as count from \"\"\" + ptype).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all column names in the data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = db.sql('SELECT * FROM ' + ptype)\n",
    "# Get the column names\n",
    "column_names = res.columns\n",
    "\n",
    "# Print the list of column names\n",
    "print(\"Column Names:\")\n",
    "for name in column_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the result to a Pandas DataFrame\n",
    "df = res.df()\n",
    "# Remove some columns before exporting in order to reduce the file size\n",
    "columns_to_drop = ['geometry', 'bbox','filename','theme', 'type','sources','version']\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Write the DataFrame to a nicely formatted JSON file\n",
    "output_file = ptype + \".json\"\n",
    "df.to_json(output_file, orient=\"records\", lines=True, indent=2)\n",
    "\n",
    "print(f\"Data written to {output_file} in nicely formatted JSON format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert geometry and write to GeoJSON with only a few attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.sql(\"\"\"COPY (\n",
    "    SELECT ST_GeomFromWKB(\"\"\" + ptype + \"\"\".geometry) as geometry, id, subtype FROM \"\"\" + ptype + \"\"\"\n",
    ") TO '\"\"\" + ptype + \"\"\".geojson'\n",
    "WITH (FORMAT GDAL, DRIVER 'GeoJSON');\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next: How to flatten the RoadType.class attribute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten the RoadType.class attribute to Segment.class\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The content below is from https://github.com/Youssef-Harby/OvertureMapsDownloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.sql(\"\"\"\n",
    "    select * from \"\"\" + ptype + \"\"\" limit 25\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the diagram of the POI data [here](https://docs.overturemaps.org/reference/places/place/). There are columns in the data that we need to preprocess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.sql(\"\"\"\n",
    "    select names, categories, confidence,brand,addresses from places limit 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, in order to find out which category it is in the categories column, we need to get the information from the data held in the \"struct\" type. You can review the document to learn about DuckDB data types.\n",
    "For example, to extract which country you are located in the \"Addresses\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.sql(\"\"\"\n",
    "    select replace(json_extract(CAST(addresses AS JSON), '$[0].country')::varchar,'\"','') as country from places limit 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "After creating a column called “country” to extract country short names, we add the extracted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "       db.sql(\"\"\"ALTER TABLE places ADD COLUMN country VARCHAR;\n",
    "              update places set country = replace(json_extract(CAST(places.addresses AS JSON), '$[0].country')::varchar,'\"','')\n",
    "\n",
    "       \"\"\")\n",
    "except duckdb.Error as e:\n",
    "    print(e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the following query to add the POI data in Turkey to a separate table and obtain the address, category, name, geometry information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.sql(\"\"\"\n",
    "       create or replace table turkey_places as (\n",
    "              select\n",
    "                     replace(json_extract(places.addresses::json,'$[0].locality'),'\"','')::varchar as locality,\n",
    "                     replace(json_extract(places.addresses::json,'$[0].region'),'\"','')::varchar as region,\n",
    "                     replace(json_extract(places.addresses::json,'$[0].postcode'),'\"','')::varchar as postcode,\n",
    "                     replace(json_extract(places.addresses::json,'$[0].freeform'),'\"','')::varchar as freeform,\n",
    "\n",
    "                     categories.main as categories_main,\n",
    "\n",
    "                     replace(json_extract(places.names::json,'$.common[0].value'),'\"','')::varchar as names,\n",
    "                     confidence,\n",
    "                     bbox,\n",
    "                     st_transform(st_point(st_y(st_geomfromwkb(geometry)),st_x(st_geomfromwkb(geometry))),'EPSG:4326','EPSG:3857') as geom\n",
    "\n",
    "\n",
    "              from places \n",
    "                     where country ='TR' \n",
    "       )\n",
    "\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.sql(\"\"\"\n",
    "select * from turkey_places limit 5\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, I will examine the POI data in Istanbul. I created two tables to obtain the POI points located within 500 m of the designated park points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.sql(\"\"\"\n",
    "    create or replace table park_ist as (\n",
    "        select * from turkey_places where locality = 'İstanbul' and categories_main='park'   \n",
    "    );\n",
    "\n",
    "    create or replace table poi_ist as (\n",
    "        select * from turkey_places where locality = 'İstanbul' and categories_main <> 'park'\n",
    "    )\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of POIs in Istanbul:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.sql(\n",
    "    \"\"\"\n",
    "select count(*) from poi_ist\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "'''\n",
    "count\n",
    "  181959\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of POIs designated as Parks in Istanbul:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.sql(\n",
    "    \"\"\"\n",
    "select count(*) from park_ist\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "'''\n",
    "count\n",
    "  492\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To query the POI points within 500 m of the points included in the park category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = db.sql(\"\"\"\n",
    "              select  poi_ist.region as poi_ist_region,poi_ist.freeform as poi_ist_freeform,poi_ist.categories_main as poi_ist_categori ,\n",
    "              park_ist.categories_main as park_categori , park_ist.names as park_names, park_ist.freeform as park_ist_freeform,\n",
    "\n",
    "              st_distance(poi_ist.geom,park_ist.geom) as dist,\n",
    "              ST_AsText(poi_ist.geom) as geom,\n",
    "              ST_AsText(park_ist.geom) as geom2\n",
    "\n",
    "              from poi_ist, park_ist \n",
    "\n",
    "              where ST_DWithin(poi_ist.geom, park_ist.geom,500) \n",
    "       \"\"\").to_df()\n",
    "\n",
    "gdf = gpd.GeoDataFrame(df,geometry= gpd.GeoSeries.from_wkt(df['geom']),crs=\"EPSG:3857\")\n",
    "gdf.to_file(\"poi.geojson\",driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "overturemapsdownloader-W8Mf4UPw-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
